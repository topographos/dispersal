[
  {
    "path": "posts/2021-01-13-intro-to-r-part-1/",
    "title": "Intro to R - Part 1",
    "description": "A Introduction to R and RStudio",
    "author": [
      {
        "name": "Michal Michalski",
        "url": "https://dispersal.rbind.io/about.html"
      }
    ],
    "date": "2021-01-06",
    "categories": [
      "R",
      "Training"
    ],
    "contents": "\nDistill is a publication format for scientific and technical writing, native to the web.\nLearn more about using Distill at https://rstudio.github.io/distill.\n\n\n\n",
    "preview": {},
    "last_modified": "2021-01-13T22:21:09+00:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-01-13-intro-to-r-part-2/",
    "title": "Intro to R - Part 2",
    "description": "Data Structures",
    "author": [
      {
        "name": "Michal Michalski",
        "url": "https://dispersal.rbind.io/about.html"
      }
    ],
    "date": "2021-01-06",
    "categories": [
      "R",
      "Training"
    ],
    "contents": "\n\nContents\nData Structures\nIntroduction\nData Types\nCharacter\nNumeric\nInteger\nLogical\n\nData Structures\nVectors\nFactors\nLists\n\nFunctions Review\nAcknowledgments\n\n\nData Structures\nIntroduction\nMost common dataset format is spreadsheet or a CSV file. Let’s start by reading in a file of archaeological surveys from the Middle East. We will load and save the data as an object named surveys:1\n\n\nsurveys = read.csv(\"data/surveys.csv\")\n\n\n\nLet’s have a look at the table:\n\nname\nabbreviation\nsites_number\nsize_km\ncountry\nAmuq Valley Regional Project\nAVRP\n178\n535\nTurkey\nBekaa Valley Survey\nBVS\n229\n2749\nLebanon\nLand of Carchemish Project Survey\nLCP\n31\n500\nSyria\nTell Hamoukar Survey\nTHS\n42\n125\nSyria\n\nNow, we can jump to exploring the dataset right away, pulling out columns using the $ operator:\n\n\nsurveys$country\n\n\n[1] \"Turkey\"  \"Lebanon\" \"Syria\"   \"Syria\"  \n\nsurveys$size_km\n\n\n[1]  535 2749  500  125\n\nWe can try other operations on the columns, for example if we discovered that each survey was actually 20 square kilometers bigger:\n\n\nsurveys$size_km + 20\n\n\n[1]  555 2769  520  145\n\nBut what about adding values of the below columns\n\n\nsurveys$size_km + surveys$country\n\n\nError in surveys$size_km + surveys$country: non-numeric argument to binary operator\n\nUnderstanding what happened here is key to successfully analyzing data in R.\nThe previous command produced an error because we tried to add for example 500 to Syria, a two different data types. Thus, to avoid this, we can check the data type of something by typing:\n\n\nclass(surveys$size_km)\n\n\n[1] \"integer\"\n\nIn R everything is an object. Objects are used to hold data values. The type of stored value is defined by data types.\nThere are six basic types in R:\ncharacter\nnumeric (real and decimal)\ninteger\nlogical\ncomplex\nraw\nThese data types can be combined to create data structures:\natomic vector\nfactor\nlist\nmatrix\narray\ndata frame\nR provides many functions to examine features of the objects, for example\nclass() - what kind of object is it (high-level)?\ntypeof() - what is the objects data type (low-level)?\nlength() - how long is it? What about two dimensional objects?\nattributes() - does it have any metadata?\nData Types\nCharacter\nWhat is the site name?\n\n\nclass(\"Tell Brak\")\n\n\n[1] \"character\"\n\nText or string are called characters.\nNumeric\nWhat is the site area?\n\n\nclass(40.1)\n\n\n[1] \"numeric\"\n\nDecimal values are called numeric.\nInteger\nWhat is the site height?\n\n\nclass(40L) # The L suffix forces the number to be an integer\n\n\n[1] \"integer\"\n\nInteger, a number written without a fractional component.In R all integers are also numeric.\nLogical\nIs it a mound? (YES/NO == TRUE/FALSE)\n\n\nis_mound = TRUE\n\n\n\nLogical values are denoted by Boolean values, TRUE or FAlSE.\nData Structures\nVectors\nVector are one-dimensional arrays that hold one type of data.\n\n\nmy_vector = vector(length = 3)\nmy_vector\n\n\n[1] FALSE FALSE FALSE\n\nA vector in R is essentially an ordered list of things, with the special condition that everything in the vector must be the same basic data type. If you do not choose the data type, it will default to logical; or, you can declare an empty vector of whatever type you like.\n\n\nanother_vector = vector(mode='character', length = 3)\n\nanother_vector\n\n\n[1] \"\" \"\" \"\"\n\nstr(another_vector)\n\n\n chr [1:3] \"\" \"\" \"\"\n\nThe somewhat cryptic output from this command indicates the basic data type found in this vector - in this case chr, character; an indication of the number of things in the vector - actually, the indexes of the vector, in this case [1:3]; and a few examples of what’s actually in the vector - in this case empty character strings. If we similarly do\n\n\nstr(surveys$sites_number)\n\n\n int [1:4] 178 229 31 42\n\nWe see that surveys$sites_number is a vector, too - the columns of data we load into R data frames are all vectors, and that’s the root of why R forces everything in a column to be the same basic data type.\nYou can also make vectors with explicit contents with the combine function:\n\n\ncombine_vector = c(178, 229, 31,42)\ncombine_vector\n\n\n[1] 178 229  31  42\n\nFactors\nLists\nFunctions Review\n\nFunction\nDescription\nread.table\nMaximum rows to print per page.\nread.csv\nMaximum rows in the table (defaults to 1000).\nread.delim\nMaximum columns in the table (defaults to 10).\nclass()\nPrint row names as part of the table.\nstr()\nreturns structure of the object\nvector()\nproduces a vector of defined mode and length\nc()\ncombine function\n\nAcknowledgments\nThis is a place to recognize people and institutions. It may also be a good place to acknowledge and cite software that makes your work possible.\n\nThis will become a hover-able footnote↩︎\n",
    "preview": {},
    "last_modified": "2021-01-24T21:49:06+00:00",
    "input_file": "intro-to-r-part-2.utf8.md"
  },
  {
    "path": "posts/2021-01-13-intro-to-r-part-3/",
    "title": "Intro to R - Part 3",
    "description": "Data Structures",
    "author": [
      {
        "name": "Michal Michalski",
        "url": "https://dispersal.rbind.io/about.html"
      }
    ],
    "date": "2021-01-06",
    "categories": [
      "R",
      "Training"
    ],
    "contents": "\n\nContents\nData Structures\nData Types\nData Structures\nFunctions Review\n\n\nData Structures\nIntroduction\nMost common dataset format is spreadsheet or a CSV file. Let’s start by reading in a file of archaeological surveys from the Middle East. We will load and save the data as an object named surveys:1\n\n\nsurveys = read.csv(\"data/surveys.csv\")\n\n\n\nLet’s have a look at the table:\n\nname\nabbreviation\nsites_number\nsize_km\ncountry\nAmuq Valley Regional Project\nAVRP\n178\n535\nTurkey\nBekaa Valley Survey\nBVS\n229\n2749\nLebanon\nLand of Carchemish Project Survey\nLCP\n31\n500\nSyria\nTell Hamoukar Survey\nTHS\n42\n125\nSyria\n\nNow, we can jump to exploring the dataset right away, pulling out columns using the $ operator:\n\n\nsurveys$country\n\n\n[1] \"Turkey\"  \"Lebanon\" \"Syria\"   \"Syria\"  \n\nsurveys$size_km\n\n\n[1]  535 2749  500  125\n\nWe can try other operations on the columns, for example if we discovered that each survey was actually 20 square kilometers bigger:\n\n\nsurveys$size_km + 20\n\n\n[1]  555 2769  520  145\n\nBut what about adding values of the below columns\n\n\nsurveys$size_km + surveys$country\n\n\nError in surveys$size_km + surveys$country: non-numeric argument to binary operator\n\nUnderstanding what happened here is key to successfully analyzing data in R.\nThe previous command produced an error because we tried to add for example 500 to Syria, a two different data types. Thus, to avoid this, we can check the data type of something by typing:\n\n\nclass(surveys$size_km)\n\n\n[1] \"integer\"\n\nIn R everything is an object. Objects are used to hold data values. The type of stored value is defined by data types.\nThere are six basic types in R:\ncharacter\nnumeric (real and decimal)\ninteger\nlogical\ncomplex\nraw\nThese data types can be combined to create data structures:\natomic vector\nfactor\nlist\nmatrix\narray\ndata frame\nR provides many functions to examine features of the objects, for example\nclass() - what kind of object is it (high-level)?\ntypeof() - what is the objects data type (low-level)?\nlength() - how long is it? What about two dimensional objects?\nattributes() - does it have any metadata?\nData Types\nCharacter\nWhat is the site name?\n\n\nclass(\"Tell Brak\")\n\n\n[1] \"character\"\n\nText or string are called characters.\nNumeric\nWhat is the site area?\n\n\nclass(40.1)\n\n\n[1] \"numeric\"\n\nDecimal values are called numeric.\nInteger\nWhat is the site height?\n\n\nclass(40L) # The L suffix forces the number to be an integer\n\n\n[1] \"integer\"\n\nInteger, a number written without a fractional component.In R all integers are also numeric.\nLogical\nIs it a mound? (YES/NO == TRUE/FALSE)\n\n\nis_mound = TRUE\n\n\n\nLogical values are denoted by Boolean values, TRUE or FAlSE.\nData Structures\nVectors\nVector are one-dimensional arrays that hold one type of data.\n\n\nmy_vector = vector(length = 3)\nmy_vector\n\n\n[1] FALSE FALSE FALSE\n\nA vector in R is essentially an ordered list of things, with the special condition that everything in the vector must be the same basic data type. If you do not choose the data type, it will default to logical; or, you can declare an empty vector of whatever type you like.\n\n\nanother_vector = vector(mode='character', length = 3)\n\nanother_vector\n\n\n[1] \"\" \"\" \"\"\n\nstr(another_vector)\n\n\n chr [1:3] \"\" \"\" \"\"\n\nThe somewhat cryptic output from this command indicates the basic data type found in this vector - in this case chr, character; an indication of the number of things in the vector - actually, the indexes of the vector, in this case [1:3]; and a few examples of what’s actually in the vector - in this case empty character strings. If we similarly do\n\n\nstr(surveys$sites_number)\n\n\n int [1:4] 178 229 31 42\n\nWe see that surveys$sites_number is a vector, too - the columns of data we load into R data frames are all vectors, and that’s the root of why R forces everything in a column to be the same basic data type.\nYou can also make vectors with explicit contents with the combine function:\n\n\ncombine_vector = c(178, 229, 31,42)\ncombine_vector\n\n\n[1] 178 229  31  42\n\nFactors\nLists\nFunctions Review\n\nFunction\nDescription\nread.table\nMaximum rows to print per page.\nread.csv\nMaximum rows in the table (defaults to 1000).\nread.delim\nMaximum columns in the table (defaults to 10).\nclass()\nPrint row names as part of the table.\nstr()\nreturns structure of the object\nvector()\nproduces a vector of defined mode and length\nc()\ncombine function\n\n\nThis will become a hover-able footnote↩︎\n",
    "preview": {},
    "last_modified": "2021-01-28T13:41:11+00:00",
    "input_file": "intro-to-r-part-3.utf8.md"
  },
  {
    "path": "posts/2019-01-05-project-proposal/",
    "title": "Project Proposal",
    "description": "The Great Dispersal - a spatio-temporal analysis of settlements patterns in the Northern Fertile Crescent from the Iron Age to the Late Islamic period.",
    "author": [
      {
        "name": "Michal Michalski",
        "url": "https://topographos.netlify.com"
      }
    ],
    "date": "2019-01-05",
    "categories": [
      "PhD"
    ],
    "contents": "\n\n1…2…3… Start\n\nBackground\nThe history of the Near East has been characterised by cycles of growth and collapse. Though periods of political and social centralization were interspersed with periods of fragmentation, the overall trend was an evolution from city-states into larger, more complex political entities (Liverani 2005). The transition from Bronze Age to Iron Age that unravelled around 1200 BC culminated in the emergence of successive Large Territorial Empires. Consequently, the long list of empires inaugurated by the Neo-Assyrians dominated the region from about the 9th century BC until the early 20th century. This period of upheaval witnessed profound social, political, economic and cultural changes. The level of urbanisation declined, trade was disrupted, and invaders appeared. Although causes of these events are not fully understood, they have been attributed to social revolution, ecological disaster, and large-scale migrations, amongst other factors (Mieroop 2015). Yet, the distinction between consequences and catalysts remains ambiguous. Moreover, archaeology still struggles to explain the underlying mechanisms of accompanying changes in landscape organization in Northern Mesopotamia and the Levant. The tell-dominated landscape of the Bronze Age was reshaped and the nucleated centres were superseded by smaller, rural settlements and occasional large cities. This structural change in settlement pattern was termed ‘The Great Dispersal’ (Wilkinson 2003). The new arrangement of space endured until the late Islamic period.\n\n\nknitr::include_graphics(\"figures/transition.png\")\n\n\n\n\nFigure 1: Spatial changes in landscape showing shift from nucleated to dispersed settlement pattern (Wilkinson, Ur, and Casana 2004).\n\n\n\nPrevious work\nImportantly, the transformation was uneven across space and time. The rain-fed steppes of Upper Mesopotamia saw the settlement dispersal in the Late Bronze Age. In contrast, the change in the Northern Levant did not occur until the Hellenistic and Roman-Byzantine periods. Therefore, the roots of the changes could differ across regions and might result from various overlapping factors. There is a definite correlation between centralization of political entities and the consequent emergence of empires in Jazira. The dispersal pattern has been attributed to political activities, such as administrative restructuring (Wilkinson 2000), creation of a ‘landscape of power’ (Bonacossi 1996), and institutional colonization (Wilkinson et al. 2005). In Jazira, the conquered population was forcibly translocated by the Neo-Assyrian state, while in the Levant a few centuries later, Rome was exercising its power and changing the local landscape by granting land to army veterans (Giorgi 2007).\nBesides organized resettlements, the movement of indigenous population or nomadic peoples may have played a role in shaping new pattern. Most recent studies emphasize mobility and the dynamics of movement as a major factor enabling social transition that led to new settlement patterns (Altaweel and Squitieri 2018). On the economic level, it has been argued that increases in settlement density were related to the commercialization of agriculture (Wilkinson, Ur, and Casana 2004). The demand for farming products in new large administrative centres may have resulted in the reorganization of the agricultural hinterland. This would explain the foundation of new villages, farmhouses or hamlets, as well as the creation of large irrigation projects (Wilkinson et al. 2005). Additionally, changes from community to private land ownership accompanied the development of a market economy linked to long-distance trade (Casana 2007). These processes that transformed the countryside in the Near East may have analogies in the Roman Empire, where stable political conditions were vital for the development of the Roman villa (Altaweel and Squitieri 2018).\nThus, it is clear that the circumstances of settlement dispersal are difficult to explain by a single framework. One reason for this is the aforementioned variation across time and space, causing doubt as to whether these events are even interrelated. There is also a gap in understanding of rural settlements due to a lack of excavations and a general bias towards large sites. Therefore, there is a need for a comprehensive inter-regional study of rural settlement patterns, which would serve as a benchmark for further research avenues.\nResearch Questions\nWhat is the timing of the ‘Great Dispersal’ across the Northern Fertile Crescent?\nWas there one dispersal or many ‘dispersals?’ Are these events interrelated?\nWhat are the processes underpinning the change?\nWhat are the long-term settlement trajectories in the Northern Fertile Crescent from the Iron Age to the Late Islamic period?\nResearch Objectives\nThe purposes of this study are twofold. Firstly, it aims to better understand the timing and mechanisms underlying ‘The Great Dispersal’ process and the consequent long-term occupation of the landscape under the rule of Later Territorial Empires in the Fertile Crescent. Secondly, it aims to develop transparent, reproducible and open workflows for analysing and visualizing archaeological survey data, dealing with so called ‘big data’ in archaeology.\nIn order to address the first objective, I aim to provide new insights into spatial and diachronic settlement trajectories in relation to:\nThe ecological landscape - by looking at correlations between variables standardized across the region, such us geomorphology, climate or vegetation.\nThe socio-political landscape - by detecting settlement patterns, hierarchy and distribution, as well as their relationships with administrative structures.\nThe economic landscape - by following the shifts in land tenure practices under state development from subsistence economy to commercial farming.\nI shall meet the second objective by harnessing cutting edge developments in Spatial Data Science. I will design reproducible workflows for dealing with archaeological survey data. I will address data management practices, the limitations of legacy-surveys, border edge issues, and artefact distribution patterns.\nData\nThis study will build upon datasets collected by the ‘Fragile Crescent’ project, covering the northern part of the Fertile Crescent. The area encompasses the Levant and Northern Mesopotamia. The database comprises legacy archaeological surveys, topographical maps, historical geographies, and satellite imagery brought into one analytical framework (Lawrence, Bradbury, and Dunford 2012). Although the project itself has ended, the database is still updated and is one of the largest academic collections of archaeological sites in the Near East. As part of my project, I will revise the current data model and database software and consider additional datasets and enhancements.\n\n\n\nFigure 2: Temporal changes in settlement density in the Northern Fertile Crescent (Lawrence, Philip & Hunt et al. 2016) - graphic was reproduced in R using supporting data.\n\n\n\nMethodology\n‘The question then becomes how best to mine, mix and otherwise analyse a potential embarrassment of riches’ (Bevan 2015, 4)\nTo answer my research question, I propose to use a selection of qualitative and quantitative methods. In doing so, I will answer a recent call to carry out an open science in archaeology built on three pillars: open access, open methods and open data (marwick_open_2017?). I propose to employ methodological developments of movement known as Spatial or Geographic Data Science. These are seen as part of a wider Data Science paradigm, though with a spatial component added to data analysis, statistics, data mining, and machine learning database manipulation (Anselin 2015). This approach also emphasises command-line interface and reproducibility (Singleton, Spielman, and Brunsdon 2016). Hence, this project will prove state of the art in coupling R language and GIS software. R is a versatile statistical language that provides an environment for data manipulation, analysis, modelling and visualisation. It also provides an ability to move seamlessly from analysis of spatial to non-spatial data (Muenchow, Lovelace, and Nowosad 2018).\n\n\nknitr::include_graphics(\"figures/data_science.png\")\n\n\n\n\nFigure 3: Data Science pipeline - a sequence of processing and analysing steps - will be at the core of project methodological framework (Grolemund and Wickham 2017).\n\n\n\nImportance of Research\nIn sum, the innovative nature of this study means that it will:\nanalyse the largest database of archaeological sites in the Near East\nresearch ‘The Great Dispersal,’ one of the most puzzling processes in ancient history\npresent a model of settlement trajectories, with an emphasis on poorly understood rural settlements in the Northern Fertile Crescent\ndesign open and reproducible procedures to analyze legacy archaeological datasets conduct cutting edge, internet-based research\nDissemination\nI plan to communicate my work and the results of my research in the following manner:\nPhd thesis, journal articles, conference presentations, posters\nAn online book or blog to serve as a ‘technical paper’ to document and discuss methodology\nAn online code repository to share and receive feedback on code and analysis\nWeb mapping to visualize selected themes of analysis\nWorkshops to share good practice of working with open source software\nTimetable\nOctober 2018 to September 2019 - In the first year, I will carry out a literature review and develop a familiarity with the data. I will focus on revising the current database management practices and enhancing the database with additional datasets.\nOctober 2019 to September 2020 - The second year will see me finalizing a new data model for the analytical framework. I will design the methodology and tools. I will also create my first visualizations to help refine the project objectives and generate questions and hypotheses about the data. The results will be presented during a progress review. This is an important step in seeking to understand the data.\nOctober 2020 to September 2021 - In the third year, I will focus on spatial analysis, data modelling, and hypothesis confirmation. I will also begin dissemination of my work through a dedicated website and blog. I will aim to receive feedback on my preliminary results and scientific code through online tools.\nOctober 2021 to September 2022- I will finalize my analysis and modelling.\nOctober 2022 to September 2023 - This year will be devoted to writing up my thesis. I will aim to give presentations at conferences and author a journal article.\nOctober 2023 to September 2024 - In the last year, I will finalise writing and and submit my doctoral thesis.\n\n\n\nFigure 4: Draft timetable showing major doctoral project milestones.\n\n\n\nFacilities, Equipment, Cost\nI do not envisage additional costs related to my project. I intend to accomplish my objectives by using free and open source software, as well as using the university’s existing IT facilities.\n\n\n\nAltaweel, Mark, and A Squitieri. 2018. Revolutionizing a {World}: {From} {Small} {States} to {Universalism} in the {Pre}-{Islamic} {Near} {East}. London: UCL Press. https://iris.ucl.ac.uk/iris/publication/1297003/1.\n\n\nAnselin, Luc. 2015. “Spatial {Data} {Science} for an {Enhanced} {Understanding} of {Urban} {Dynamics}.” http://citiespapers.ssrc.org/.\n\n\nBevan, Andrew. 2015. “The data deluge.” Antiquity 89 (348): 1473–84. https://doi.org/10.15184/aqy.2015.102.\n\n\nBonacossi, Daniele Morandi. 1996. “‘{Landscapes} of {Power}’ {The} {Political} {Organisation} of space in the lower {Habur} valley in the {Neo}-{Assyrian}.” Bulletin of the State Archives of Assyria 10 (2): 15–49.\n\n\nCasana, Jesse. 2007. “Structural {Transformations} in {Settlement} {Systems} of the {Northern} {Levant}.” American Journal of Archaeology 111 (2): 195–221. http://www.jstor.org/stable/40037272.\n\n\nGiorgi, Andrea U De. 2007. “The formation of a {Roman} landscape: the case of {Antioch}.” Journal of Roman Archaeology 20: 283–98. https://doi.org/10.1017/S1047759400005420.\n\n\nGrolemund, Garrett, and Hadley Wickham. 2017. R for {Data} {Science}. http://r4ds.had.co.nz/.\n\n\nLawrence, D, J Bradbury, and R Dunford. 2012. “Chronology, uncertainty and {GIS} : a methodology for characterising and understanding landscapes of the ancient {Near} {East}.” eTopoi : Journal for Ancient Studies. Special Volume 3 (January): 1007–14. https://doi.org/http://dro.dur.ac.uk/23510/1/23510.pdf.\n\n\nLiverani, Mario. 2005. “Historical Overview.” In A {Companion} to the {Ancient} {Near} {East}, edited by Daniel C Snell, 1–19. Blackwell Publishing Ltd. https://doi.org/10.1002/9780470997086.ch1.\n\n\nMieroop, Marc Van De. 2015. A {History} of the {Ancient} {Near} {East}, ca. 3000-323 {BC}. John Wiley & Sons.\n\n\nMuenchow, J, R Lovelace, and J Nowosad. 2018. Geocomputation with {R}. https://geocompr.robinlovelace.net.\n\n\nSingleton, Alex David, Seth Spielman, and Chris Brunsdon. 2016. “Establishing a framework for {Open} {Geographic} {Information} science.” International Journal of Geographical Information Science 30 (8): 1507–21. https://doi.org/10.1080/13658816.2015.1137579.\n\n\nWilkinson, T J. 2000. “Regional {Approaches} to {Mesopotamian} {Archaeology}: {The} {Contribution} of {Archaeological} {Surveys}.” Journal of Archaeological Research 8 (3): 219–67. https://doi.org/10.1023/A:1009487620969.\n\n\n———. 2003. Archaeological {Landscapes} of the {Near} {East}. Tucson.\n\n\nWilkinson, T J, Jason A Ur, and Jesse Casana. 2004. “From {Nucleation} to {Dispersal}: {Trends} in {Settlement} {Pattern} in the {Northern} {Fertile} {Crescent}.” In Side-by-{Side} {Survey}: {Comparative} {Regional} {Studies} in the {Mediterranean} {World}, edited by John Cherry and Susan Alcock, 198–205. Oxford: Oxbow Books.\n\n\nWilkinson, T J, Jason Ur, Eleanor Barbanes Wilkinson, and Mark Altaweel. 2005. “Landscape and {Settlement} in the {Neo}-{Assyrian} {Empire}.” Bulletin of the American Schools of Oriental Research, no. 340: 23–56. http://www.jstor.org/stable/25066913.\n\n\n\n\n",
    "preview": "posts/2019-01-05-project-proposal/figures/transition.png",
    "last_modified": "2021-01-04T19:40:12+00:00",
    "input_file": {},
    "preview_width": 867,
    "preview_height": 380
  }
]
